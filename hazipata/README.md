# はじめてのパターン認識
読んでて調べた内容をまとめる  

ボートストラップ法  
https://qiita.com/saltcooky/items/451b96b3f346cb93a0b4  

情報量基準（AIC、BIC）  
https://research.miidas.jp/2019/04/aic%E3%81%A8bic%EF%BC%9F%E6%83%85%E5%A0%B1%E9%87%8F%E5%9F%BA%E6%BA%96%E3%81%A8%E3%81%AF%EF%BC%9F/  
AIC（赤池情報量基準）:統計的モデルの予測性の良さを、観測値と理論値の差（残差）を用いて評価する統計量  
尤度L、モデル中のパラメタ数pとすると、AIC = -2lnL + 2p  
BIC : 、回帰モデルが多くの項を含みすぎることに対してペナルティを課するもの  
Lは尤度関数、nは標本の大きさあるいは観測の数、kは母数あるいは独立変数の数とすると BIC =-2lnL + kln(n)  

最近傍法の章の詳しい説明  
https://www.slideshare.net/moa108/5-kknn  
 
SVMの詳しいスライド  
https://www.slideshare.net/moa108/8-28571831  
https://www.slideshare.net/mknh1122/svm-13623887  

主成分分析の解説  
https://statistics.co.jp/reference/software_R/statR_9_principal.pdf  
https://qiita.com/NoriakiOshita/items/460247bb57c22973a5f0  
共分散行列の固有値問題に着地できる理由を明記した解説  
https://nehori.com/nikki/2019/04/22/post-10464/  
http://ibis.t.u-tokyo.ac.jp/suzuki/lecture/2015/dataanalysis/L7.pdf   

１０章クラスタリング解説スライド  
https://www.slideshare.net/yamakatu/hajipata10  

決定木とランダムフォレストの解説スライド  
https://www.slideshare.net/teppeibaba5/ss-37143977  
 
 
 
  　
   
  
