{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "[0 1 2 3 4 1 5 6]\n"
     ]
    }
   ],
   "source": [
    "text ='You say goodbye and I say Hello.'\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "words = text.split(' ')\n",
    "print(words)\n",
    "\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "        \n",
    "print(word_to_id)\n",
    "\n",
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "print(corpus)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067758832467\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    '''共起行列の作成\n",
    "\n",
    "    :param corpus: コーパス（単語IDのリスト）\n",
    "    :param vocab_size:語彙数\n",
    "    :param window_size:ウィンドウサイズ（ウィンドウサイズが1のときは、単語の左右1単語がコンテキスト）\n",
    "    :return: 共起行列\n",
    "    '''\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "    \n",
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps)\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps)    \n",
    "    return np.dot(nx, ny)\n",
    "\n",
    "text ='You say goodbye and I say Hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067758832467\n",
      " i: 0.7071067758832467\n",
      " hello: 0.7071067758832467\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    '''類似単語の検索\n",
    "\n",
    "    :param query: クエリ（テキスト）\n",
    "    :param word_to_id: 単語から単語IDへのディクショナリ\n",
    "    :param id_to_word: 単語IDから単語へのディクショナリ\n",
    "    :param word_matrix: 単語ベクトルをまとめた行列。各行に対応する単語のベクトルが格納されていることを想定する\n",
    "    :param top: 上位何位まで表示するか\n",
    "    '''\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return\n",
    "        \n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "[[0.        1.8073549 0.        0.        0.        0.        0.       ]\n",
      " [1.8073549 0.        0.8073549 0.        0.8073549 0.8073549 0.       ]\n",
      " [0.        0.8073549 0.        1.8073549 0.        0.        0.       ]\n",
      " [0.        0.        1.8073549 0.        1.8073549 0.        0.       ]\n",
      " [0.        0.8073549 0.        1.8073549 0.        0.        0.       ]\n",
      " [0.        0.8073549 0.        0.        0.        0.        2.807355 ]\n",
      " [0.        0.        0.        0.        0.        2.807355  0.       ]]\n",
      "[0 1 0 0 0 0 0]\n",
      "[0.        1.8073549 0.        0.        0.        0.        0.       ]\n",
      "[-3.4094876e-01 -1.1102230e-16 -3.8857806e-16 -1.2051624e-01\n",
      "  0.0000000e+00  9.3232495e-01  2.2259700e-16]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    '''PPMI（正の相互情報量）の作成\n",
    "\n",
    "    :param C: 共起行列\n",
    "    :param verbose: 進行状況を出力するかどうか\n",
    "    :return:\n",
    "    '''\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100 + 1) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    return M\n",
    "\n",
    "W = ppmi(C)\n",
    "print(C)\n",
    "print(W)\n",
    "\n",
    "U, S, V = np.linalg.svd(W)\n",
    "print(C[0])\n",
    "print(W[0])\n",
    "print(U[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:, 0], U[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "corpus size: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('corpus size:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting  co-occurrence ...\n",
      "calculating PPMI ...\n",
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "calculating SVD ...\n",
      "use truncated SVD\n",
      "\n",
      "[query] you\n",
      " i: 0.6369001865386963\n",
      " do: 0.5450039505958557\n",
      " anybody: 0.5402004718780518\n",
      " we: 0.5401972532272339\n",
      " me: 0.517218828201294\n",
      "\n",
      "[query] year\n",
      " next: 0.6155991554260254\n",
      " quarter: 0.6020523309707642\n",
      " last: 0.5888384580612183\n",
      " month: 0.5676209926605225\n",
      " earlier: 0.5586792826652527\n",
      "\n",
      "[query] car\n",
      " auto: 0.6145146489143372\n",
      " cars: 0.5449913144111633\n",
      " luxury: 0.5429535508155823\n",
      " truck: 0.5037345886230469\n",
      " rental: 0.464263379573822\n",
      "\n",
      "[query] toyota\n",
      " nissan: 0.6901456713676453\n",
      " motor: 0.6892493963241577\n",
      " motors: 0.6845290660858154\n",
      " lexus: 0.6387988924980164\n",
      " honda: 0.6055952310562134\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import most_similar, create_co_matrix, ppmi\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('counting  co-occurrence ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    # truncated SVD (fast!)\n",
    "    print('use truncated SVD')\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                             random_state=None)\n",
    "except ImportError:\n",
    "    # SVD (slow)\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
