{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
=======
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# This is the path to the image you want to transform.\n",
    "target_image_path = '/home/nagae/study/deep-learning-with-python-notebooks/portrait3.jpg'\n",
    "# This is the path to the style image.\n",
    "style_reference_image_path = '/home/nagae/study/deep-learning-with-python-notebooks/himawari.jpg'\n",
    "\n",
    "# Dimensions of the generated picture.\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = 400\n",
    "img_width = int(width * img_height / height)"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequence: 200278\n",
      "unique characters: 57\n"
     ]
    }
   ],
   "source": [
    "maxlen=60\n",
    "step=3\n",
    "sentence=[]\n",
    "next_chars=[]\n",
    "\n",
    "for i in range(0,len(text)-maxlen,step):\n",
    "    sentence.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "\n",
    "print('number of sequence:',len(sentence))\n",
    "\n",
    "chars=sorted(list(set(text)))\n",
    "print('unique characters:',len(chars))\n",
    "\n",
    "char_indices=dict((char,chars.index(char)) for char in chars)\n",
    "\n",
    "x=np.zeros((len(sentence),maxlen,len(chars)),dtype=np.bool)\n",
    "y=np.zeros((len(sentence),len(chars)),dtype=np.bool)\n",
    "\n",
    "for i,sen in enumerate(sentence):\n",
    "    for t,char in enumerate(sen):\n",
    "        x[i,t,char_indices[char]]=1\n",
    "    y[i,char_indices[next_chars[i]]]=1"
=======
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 57)                7353      \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "model=keras.models.Sequential()\n",
    "model.add(layers.LSTM(128,input_shape=(maxlen,len(chars))))\n",
    "model.add(layers.Dense(len(chars),activation='softmax'))\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=0.01),\n",
    "              loss='categorical_crossentropy')\n",
    "model.summary()"
=======
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "target_image=K.constant(preprocess_image(target_image_path))\n",
    "style_reference_image=K.constant(preprocess_image(style_reference_image_path))\n",
    "\n",
    "combination_image=K.placeholder((1,img_height,img_width,3))\n",
    "\n",
    "input_tensor=K.concatenate([target_image,style_reference_image,combination_image],axis=0)\n",
    "\n",
    "model=vgg19.VGG19(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
    "\n"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
=======
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base,combination):\n",
    "    return K.sum(K.square(combination-base))\n",
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = K.square(\n",
    "        x[:, :img_height - 1, :img_width - 1, :] - x[:, 1:, :img_width - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_height - 1, :img_width - 1, :] - x[:, :img_height - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 67,
=======
   "execution_count": 57,
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "epoch 1\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 66s 330us/step - loss: 1.9641\n",
      "--- Generating with seed: \"he who has thought out this possibility to its\n",
      "ultimate conc\"\n",
      "------ temperature: 0.2\n",
      "he who has thought out this possibility to its\n",
      "ultimate concertional and the command the course for the compassion of the been a something the compand the soul the courte of the command the still and the courter the comition of the look and the\n",
      "still and the sections of the existing the something the courte the still and the compart the soul the something the sechess the compals a sout it is a still and been a thist and secher the command the soul its and \n",
      "------ temperature: 0.5\n",
      "ll and been a thist and secher the command the soul its and the most conscience, it is the edeal caul its more been the more fact the self the self who and which the pastionable the\n",
      "downational the derelly which it the very great the conditional and experience more the all the really another and the mess that the spirit of the thist a too-more the most the secrestical with the fainical and the compart and and its more the more the sempose which the stimise\n",
      "------ temperature: 1.0\n",
      "part and and its more the more the sempose which the stimise,\n",
      "where aast and likes the\n",
      "supsymptives, and peesiful and\n",
      "leasmes relunionare hasgonable, that it\n",
      "defeil\n",
      "to danes\n",
      "of ateming and lasiner respect be aterary to all geous, hood, we.rend he dess above instinctifrary pospuntifisicy maue its\n",
      "it came ad atatide this theun falsead\n",
      "expested saure inderlegnrine, all other bleak at feel (owr where be which recodeding kund alselied bacd it\n",
      "it were and elutio\n",
      "------ temperature: 1.2\n",
      "be which recodeding kund alselied bacd it\n",
      "it were and elutionaligys9iting of state fe(let sfirm through, vertabte\" the otharnt man, with there will,idecting\n",
      "pposerted like's urmatry tse\n",
      "at chols\n",
      "even\n",
      "woucks xpict yor, did cautured would is, he could of\n",
      "\" the havould spostinative,e with, the\n",
      "equary maintyiblifure his quessionical sciepeionate indertiond bred mogal the cany way person which leseehus, itseefully bif thene are of willned and dostal, is, mamosi\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 65s 327us/step - loss: 1.6230\n",
      "--- Generating with seed: \"m, that is to say, to a movement which,\n",
      "historically conside\"\n",
      "------ temperature: 0.2\n",
      "m, that is to say, to a movement which,\n",
      "historically considered to the spirit, the predection of the species to the species and in the proted to the present of the profound to does the readed to the tree of the more supposed to the philosophy the predection of the sense of the explanes and the desire to the species and and and in the more in the desired to the strong and strong to the interestion of the moral and supposed to the spirit, to species and in t\n",
      "------ temperature: 0.5\n",
      "of the moral and supposed to the spirit, to species and in the sense the past, any will to doy of the predeption of the some of the species comes and from a doing, and and\n",
      "strong they is the strong of the species. the strong of spirits and doend something in all to the suppessible, and what is an and the case of the morally to the becomes it is not the contimanism of the taste to all spiritual only to be according to the last they liter some at possible--w\n",
      "------ temperature: 1.0\n",
      "y to be according to the last they liter some at possible--what self, \"manks, the foll\" case: the \"\"soulds original speaker as they temmorpes our mind whuch knows. conduct himself? to exprainity does ttroughner it taskes the eprops himself that so sense of him who\n",
      "scholor of his i and in cognise will to folly onesemor. how is man elstencinity.\n",
      "\n",
      "-an ones more idea to\n",
      "from\n",
      "dinalles stooy, to to\n",
      "hund and nhemotically almore, in all for the appearod to tiun al\n",
      "------ temperature: 1.2\n",
      " and nhemotically almore, in all for the appearod to tiun all, would bit glo, is emagidesismed as douttle decorganian trim,\n",
      "a clen frimulis, they hasseded!ull\n",
      "blouding\n",
      "remorps far-go thim times even this wordem be whoen its evilfoning in bediency,\n",
      "an pylisou,\n",
      "                  l et jugh, onceved how\n",
      "mupathd this him umwillessive, a fored\n",
      "it, and of trecthy,\n",
      "his futt, his not upject lit considsruse itmon inselfing in as\n",
      "fron then benorition, he odvedsawatis\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 66s 330us/step - loss: 1.5349\n",
      "--- Generating with seed: \"y, or an individual has lived, the \"divining instinct\" for t\"\n",
      "------ temperature: 0.2\n",
      "y, or an individual has lived, the \"divining instinct\" for the superiorable of the standanding the standard and and and and the standard of the such a highest and and and in the string the standard of the such and a soul, and the man and the such a so the more in the freedom of the such a desires and and in the string the and and and and and and a standard of the string in the standard of the freed and the standard of the desires of the standard of the str\n",
      "------ temperature: 0.5\n",
      "d and the standard of the desires of the standard of the string of its more should\n",
      "not the according the thind and their\n",
      "words of the supersting of their such and as the make the master of the really the to may be and without their\n",
      "completing to do not so in the manal, but his fascious and such as the values of indemances, the stander for the sensual of his still uty for the such the sinismed the believe, the existing for the through make the respecting th\n",
      "------ temperature: 1.0\n",
      "believe, the existing for the through make the respecting thin, and the vicionalism \"happies whether, as he mading--it\n",
      "good wild certain siture the -also must tomething and of manwald oeslietial discriving mind bestray god iponds. and in accordeven to arnenscal words and not dy of it armiss\n",
      "of the sciences ours: its notredies, a the grestiation: on the ecthes.\n",
      "\n",
      "\n",
      "al\n",
      "suchiner, what mi? bureth rules\"\n",
      "fine? (gets for the civalor phopovition\" to its else umagme\n",
      "------ temperature: 1.2\n",
      "\n",
      "fine? (gets for the civalor phopovition\" to its else umagmeng free, on thinks if to obxided in\n",
      "e; human\n",
      "smally theyraying wild! but i and lay, more1homous, nobleated existedwed: true?\n",
      "untuce.am, made for a\n",
      "pay \"recondecting\n",
      "our ot\n",
      "nocuremsmry, our penileness or evi\n",
      "worevered dstain apire mous atherto hildh, notruntors-gown avount heres.\" hu falso! with proposibl elue bors.--noolowething e.\n",
      "perhaps:.. whhenneattering subeond\" upine say-moru politic let =us\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 66s 330us/step - loss: 1.4910\n",
      "--- Generating with seed: \" disciplinary means whereby the european spirit has\n",
      "attained\"\n",
      "------ temperature: 0.2\n",
      " disciplinary means whereby the european spirit has\n",
      "attained and the process of the present and the most be and the promise the promise to be and a process, and also a delicate of the power and into and a soul and the account of the belief in the same the greater in the same the same the stronged and the process of the conditionally and the present and and the disposence of the strongence of the chasted and the freedom of the conditions with the sense to t\n",
      "------ temperature: 0.5\n",
      "hasted and the freedom of the conditions with the sense to the sense man in the work and the power of the forment, because of the morality as in which the belief in the bleing to the extra-bqual justice and the seems and the more with the delicate and the even if the belief an and cording the thing of the serfited\n",
      "and a deepts and something the thing really the\n",
      "reals and explanting exceptional and sansfers of the workenity believes in entire and the fact d\n",
      "------ temperature: 1.0\n",
      " sansfers of the workenity believes in entire and the fact diend\n",
      " queply position of our ourstrace, account of the edota son\n",
      "always real \"excreving it may bithly believed on they must always\n",
      "cau been, will hing.--the yet new does here hear the siey creous willidy in effect,\" a create of chastestly of the has for hisipy the world adpirificated\n",
      "for a\n",
      "most\n",
      "modern to spirits.=--them laadd! (the timilow, and the pertaint to me as modelty with the\n",
      "s -krosts its \n",
      "------ temperature: 1.2\n",
      "w, and the pertaint to me as modelty with the\n",
      "s -krosts its have not disposit bayed, from \"an) head audottake to\n",
      "thred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with been responson audide,sgeptes,, listonters (eletkable oth oneself.\n",
      "\n",
      "ta advaction. knows,\" the perceivable and swill; that is varelon. bow.\n",
      "\n",
      ", errorness believe. that o.her. pe(se fassimation oatwions a feels cause, with a neissfulance ecologient cratition patrsiprairly beceensc: putakised\n",
      "science,--a\n",
      "sam\n",
      "findord fromlining\n",
      "everything \n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 67s 332us/step - loss: 1.4614\n",
      "--- Generating with seed: \" and shape; we find it so\n",
      "much easier to fancy the chance of\"\n",
      "------ temperature: 0.2\n",
      " and shape; we find it so\n",
      "much easier to fancy the chance of the same as a distinct of the truth and the same with the interest it is a superion of the comprehension of the interral in the subject of the expering and as the readily the standard and as the superionate and interesting the subtlitude of the the the precisely and and all the standard and the exist and the experience of the experience and the have the dest and and the interest and into the comp\n",
      "------ temperature: 0.5\n",
      "and the have the dest and and the interest and into the compurtical may be as most may be against the contradity of the extence of the object has to the entire it with the heart all the acts of a fact and the same time the moteration of the interest and according of the same against was a higher in the superionity to be and which the precisely, for all the subtlse of the entient the individual is not had trid for the assume the experience of the high to hi\n",
      "------ temperature: 1.0\n",
      "not had trid for the assume the experience of the high to his common diffact of plicour involunten and made upon future voluntarily more powery of his careity of the\n",
      "hereoralay about the way \n",
      "rassed be that\n",
      "a chroughtings--it right\n",
      "as may and ssciehd inmost good indication of an imper, profound of heaverby of mint, affor\n",
      "dreams just itself in the promifies, of our jelusious concelvent\n",
      "\n",
      "nimes, in it, notakers over utility of the toobleness, in meanitical. t\n",
      "------ temperature: 1.2\n",
      "t, notakers over utility of the toobleness, in meanitical. thile\n",
      "mivening, futude oud baswing\n",
      "oment: the moterateneds has\n",
      "lair us e not alood or more dogad of his awact in poveritient; losier than clos upon that he outafrial result as if no doble; in ideas precievaocre; instincts, have been variation of lany.\n",
      "\n",
      "he deasrest of\n",
      "good in german false\"d?\n",
      "\"poythary\n",
      "being as unmystancy the\n",
      "cleseach simply  gening of freates of all parterable made know, with he lea\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 66s 328us/step - loss: 1.4399\n",
      "--- Generating with seed: \"ly\n",
      "\"literature\"--something which has not grown in germany, a\"\n",
      "------ temperature: 0.2\n",
      "ly\n",
      "\"literature\"--something which has not grown in germany, and when the superficism of the more in the fact the indifference the same the fact and the more and the feeling of the fact the profound and the false to the more and the precisely the more and the good and the fact and the fall in the precisely and the more in the more and the commined the cause the spirit and the entire and the same the germanisy of the more in the fact in the such a more desire\n",
      "------ temperature: 0.5\n",
      " germanisy of the more in the fact in the such a more desires and more sentiment they in the flelty, there is a expedient, in a thing of the fathers, and it is there is been spirits and who profolors and as in the experience, the generally indifice of the first in the words. he was not been many and manifes and places of the words and still and the generally the sense of the matter we is more there is a man and the words and the one is not precisely its ow\n",
      "------ temperature: 1.0\n",
      "e is a man and the words and the one is not precisely its own dailness\n",
      "itself. it is the pleasural vanger of old himself--in shortd and regard uyoxes of elsess is\n",
      "a the referely inagratic people wich\n",
      "far will a allummwht tham take affuce of life and calling\n",
      "than because the\n",
      "mowsm their morewame of their naturally and right digtluation to bother and beinn at the errore--such donese-distingly fallings himself, i magity, the\n",
      "evolution. and a sughter the misin\n",
      "------ temperature: 1.2\n",
      "gs himself, i magity, the\n",
      "evolution. and a sughter the misinin still hiss voles. some\n",
      "him, moder all to insporicianisms, as imterially! accidean complusion ino-perilogically reanm orternper havefming yes vitice, the degregation to senoul: in utmern first of\n",
      "the caurous to least some gain himself that to belip; the freelomsn\n",
      "closthm if\n",
      "mianses, sypte in eying of natkrigation in\n",
      "europeally notmous anstrmhe, there-germanoy-in, destrualess been must before tyd\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "166272/200278 [=======================>......] - ETA: 11s - loss: 1.4204"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-9486ed95c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     model.fit(x, y,\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               epochs=1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Select a text seed at random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
=======
    "# Dict mapping layer names to activation tensors\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "# Name of layer used for content loss\n",
    "content_layer = 'block5_conv2'\n",
    "# Name of layers used for style loss\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "# Weights in the weighted average of the loss components\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "\n",
    "# Define the loss by adding all components to a `loss` variable\n",
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict[content_layer]\n",
    "target_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss += content_weight * content_loss(target_image_features,\n",
    "                                      combination_features)\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(style_layers)) * sl\n",
    "    \n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 58,
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 26s 0us/step\n"
=======
      "(3, 25, 37, 512)\n"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "model=inception_v3.InceptionV3(weights='imagenet',include_top=False)\n"
=======
    "print(layer_features[:,:,:,:].shape)"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_contributions={\n",
    "    'mixed2':5,\n",
    "    'mixed1':3.,\n",
    "    'mixed7':4.,\n",
    "    'mixed6':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict=dict([(layer.name,layer) for layer in model.layers])\n",
    "\n",
    "loss=K.variable(0.)\n",
    "\n",
    "for layer_name in layer_contributions:\n",
    "    coeff=layer_contributions[layer_name]\n",
    "    \n",
    "    activation=layer_dict[layer_name].output\n",
    "    \n",
    "    scaling=K.prod(K.cast(K.shape(activation),'float32'))\n",
    "    \n",
    "    loss+=coeff*K.sum(K.square(activation[:,2:-2,2:-2,:]))/scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_14:0' shape=(4,) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.cast(K.shape(activation),'float32')"
=======
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream=model.input\n",
    "\n",
    "grads=K.gradients(loss,dream)[0]\n",
    "\n",
    "grads/=K.maximum(K.mean(K.abs(grads)),1e-7)\n",
    "\n",
    "outputs=[loss,grads]\n",
    "fetch_loss_and_grads=K.function([dream],outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2],\n",
    "               1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Util function to open, resize and format pictures\n",
    "    # into appropriate tensors.\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Util function to convert a tensor into a valid image.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
=======
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gradients of the generated image wrt the loss\n",
    "grads = K.gradients(loss, combination_image)[0]\n",
    "\n",
    "# Function to fetch the values of the current loss and the current gradients\n",
    "fetch_loss_and_grads = K.function([combination_image], [loss, grads])\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 61,
   "metadata": {},
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Processing image shape (244, 326)\n",
      "...Loss value at 0 : 4.4964733\n",
      "...Loss value at 1 : 4.6258883\n",
      "...Loss value at 2 : 5.1202583\n",
      "...Loss value at 3 : 5.702804\n",
      "...Loss value at 4 : 6.230511\n",
      "...Loss value at 5 : 6.769969\n",
      "...Loss value at 6 : 7.2971716\n",
      "...Loss value at 7 : 7.846443\n",
      "...Loss value at 8 : 8.361845\n",
      "...Loss value at 9 : 8.904067\n",
      "...Loss value at 10 : 9.429545\n",
      "...Loss value at 11 : 9.927627\n",
      "...Loss value at 12 : 10.420116\n",
      "...Loss value at 13 : 10.885595\n",
      "...Loss value at 14 : 11.353413\n",
      "...Loss value at 15 : 11.794626\n",
      "...Loss value at 16 : 12.256305\n",
      "...Loss value at 17 : 12.686205\n",
      "...Loss value at 18 : 13.137896\n",
      "...Loss value at 19 : 13.499201\n",
      "Processing image shape (342, 457)\n"
=======
      "Start of iteration 0\n",
      "Current loss value: 7721092000.0\n",
      "Image saved as style_transfer_result_at_iteration_0.png\n",
      "Iteration 0 completed in 13s\n",
      "Start of iteration 1\n"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/home/nagae/anaconda3/envs/gpu-env/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nagae/anaconda3/envs/gpu-env/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
=======
      "/home/nagae/.conda/envs/gpu-env/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "...Loss value at 0 : 5.794875\n",
      "...Loss value at 1 : 7.166977\n",
      "...Loss value at 2 : 8.221695\n",
      "...Loss value at 3 : 9.053541\n",
      "...Loss value at 4 : 9.863527\n",
      "...Loss value at 5 : 10.605282\n",
      "...Loss value at 6 : 11.277155\n",
      "...Loss value at 7 : 11.929715\n",
      "...Loss value at 8 : 12.54751\n",
      "...Loss value at 9 : 13.148652\n",
      "...Loss value at 10 : 13.69611\n",
      "...Loss value at 11 : 14.299334\n",
      "...Loss value at 12 : 14.797185\n",
      "...Loss value at 13 : 15.329584\n",
      "...Loss value at 14 : 15.824842\n",
      "...Loss value at 15 : 16.321638\n",
      "...Loss value at 16 : 16.80609\n",
      "...Loss value at 17 : 17.292713\n",
      "...Loss value at 18 : 17.731693\n",
      "...Loss value at 19 : 18.183054\n",
      "Processing image shape (480, 640)\n",
      "...Loss value at 0 : 6.5498133\n",
      "...Loss value at 1 : 8.19388\n",
      "...Loss value at 2 : 9.417133\n",
      "...Loss value at 3 : 10.383434\n",
      "...Loss value at 4 : 11.304745\n",
      "...Loss value at 5 : 12.153287\n",
      "...Loss value at 6 : 12.961979\n",
      "...Loss value at 7 : 13.709342\n",
      "...Loss value at 8 : 14.372248\n",
      "...Loss value at 9 : 15.058378\n",
      "...Loss value at 10 : 15.70222\n",
      "...Loss value at 11 : 16.29959\n",
      "...Loss value at 12 : 16.901627\n",
      "...Loss value at 13 : 17.50115\n",
      "...Loss value at 14 : 18.059032\n",
      "...Loss value at 15 : 18.63079\n",
      "...Loss value at 16 : 19.162083\n",
      "...Loss value at 17 : 19.685362\n",
      "...Loss value at 18 : 20.171513\n",
      "...Loss value at 19 : 20.700768\n"
=======
      "Current loss value: 4435499000.0\n",
      "Image saved as style_transfer_result_at_iteration_1.png\n",
      "Iteration 1 completed in 13s\n",
      "Start of iteration 2\n",
      "Current loss value: 3416183000.0\n",
      "Image saved as style_transfer_result_at_iteration_2.png\n",
      "Iteration 2 completed in 13s\n",
      "Start of iteration 3\n",
      "Current loss value: 2863189800.0\n",
      "Image saved as style_transfer_result_at_iteration_3.png\n",
      "Iteration 3 completed in 13s\n",
      "Start of iteration 4\n",
      "Current loss value: 2501868000.0\n",
      "Image saved as style_transfer_result_at_iteration_4.png\n",
      "Iteration 4 completed in 13s\n",
      "Start of iteration 5\n",
      "Current loss value: 2195233800.0\n",
      "Image saved as style_transfer_result_at_iteration_5.png\n",
      "Iteration 5 completed in 13s\n",
      "Start of iteration 6\n",
      "Current loss value: 1954489500.0\n",
      "Image saved as style_transfer_result_at_iteration_6.png\n",
      "Iteration 6 completed in 13s\n",
      "Start of iteration 7\n",
      "Current loss value: 1778928800.0\n",
      "Image saved as style_transfer_result_at_iteration_7.png\n",
      "Iteration 7 completed in 13s\n",
      "Start of iteration 8\n",
      "Current loss value: 1595470800.0\n",
      "Image saved as style_transfer_result_at_iteration_8.png\n",
      "Iteration 8 completed in 14s\n",
      "Start of iteration 9\n",
      "Current loss value: 1460737000.0\n",
      "Image saved as style_transfer_result_at_iteration_9.png\n",
      "Iteration 9 completed in 13s\n",
      "Start of iteration 10\n",
      "Current loss value: 1324757000.0\n",
      "Image saved as style_transfer_result_at_iteration_10.png\n",
      "Iteration 10 completed in 14s\n",
      "Start of iteration 11\n",
      "Current loss value: 1211638300.0\n",
      "Image saved as style_transfer_result_at_iteration_11.png\n",
      "Iteration 11 completed in 14s\n",
      "Start of iteration 12\n",
      "Current loss value: 1075659800.0\n",
      "Image saved as style_transfer_result_at_iteration_12.png\n",
      "Iteration 12 completed in 14s\n",
      "Start of iteration 13\n",
      "Current loss value: 976177540.0\n",
      "Image saved as style_transfer_result_at_iteration_13.png\n",
      "Iteration 13 completed in 14s\n",
      "Start of iteration 14\n",
      "Current loss value: 878748700.0\n",
      "Image saved as style_transfer_result_at_iteration_14.png\n",
      "Iteration 14 completed in 14s\n",
      "Start of iteration 15\n",
      "Current loss value: 801125700.0\n",
      "Image saved as style_transfer_result_at_iteration_15.png\n",
      "Iteration 15 completed in 14s\n",
      "Start of iteration 16\n",
      "Current loss value: 738298700.0\n",
      "Image saved as style_transfer_result_at_iteration_16.png\n",
      "Iteration 16 completed in 15s\n",
      "Start of iteration 17\n",
      "Current loss value: 682436540.0\n",
      "Image saved as style_transfer_result_at_iteration_17.png\n",
      "Iteration 17 completed in 14s\n",
      "Start of iteration 18\n",
      "Current loss value: 625329200.0\n",
      "Image saved as style_transfer_result_at_iteration_18.png\n",
      "Iteration 18 completed in 15s\n",
      "Start of iteration 19\n",
      "Current loss value: 574562200.0\n",
      "Image saved as style_transfer_result_at_iteration_19.png\n",
      "Iteration 19 completed in 14s\n"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import numpy as np\n",
    "\n",
    "# Playing with these hyperparameters will also allow you to achieve new effects\n",
    "\n",
    "step = 0.01  # Gradient ascent step size\n",
    "num_octave = 3  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 20  # Number of ascent steps per scale\n",
    "\n",
    "# If our loss gets larger than 10,\n",
    "# we will interrupt the gradient ascent process, to avoid ugly artifacts\n",
    "max_loss = 100.\n",
    "\n",
    "# Fill this to the path to the image you want to use\n",
    "base_image_path = '/home/nagae/study/deep-learning-with-python-notebooks/deepdream.jpg'\n",
    "\n",
    "# Load the image into a Numpy array\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "# We prepare a list of shape tuples\n",
    "# defining the different scales at which we will run gradient ascent\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "# Reverse list of shapes, so that they are in increasing order\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# Resize the Numpy array of the image to our smallest scale\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "\n",
    "save_img(img, fname='final_dream.png')"
=======
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "import time\n",
    "\n",
    "result_prefix = 'style_transfer_result'\n",
    "iterations = 20\n",
    "\n",
    "# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss.\n",
    "# This is our initial state: the target image.\n",
    "# Note that `scipy.optimize.fmin_l_bfgs_b` can only process flat vectors.\n",
    "x = preprocess_image(target_image_path)\n",
    "x = x.flatten()\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x,\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # Save current generated image\n",
    "    img = x.copy().reshape((img_height, img_width, 3))\n",
    "    img = deprocess_image(img)\n",
    "    fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
>>>>>>> 43ad06a772d2d3e8e4309e642e03fdbf48702ea1
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
